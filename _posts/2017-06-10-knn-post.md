---
layout: post
title:  "KNN Algorithm"
date:   2017-06-10
excerpt: ""
tag:
- KNN
- Machine Learning
- Supervised Learning
comments: true
published: true
---
### Introduction
KNN algorithm is a supervised learning algorithm which we store training dataset (labeled) in the training time. And in the test time, we compare distance of the test data with every
every each data in the training dataset, then we select the k (hyperparameter) nearest training examples to classify our test data. The most frequent label of these k training examples, is used to classify
the test data. So the main drawback here is that since there is not actual training (because we just store the data), we need to compare distance with every training data, and as your training data is increasing,
so is your test time (linearly). The other disadvantage is that rgb values are used to measure the distance and this results with color matching, e.g. picture of the airplane on the air mostly have blue color because
of the sky and a ship on the ocean may also have blue background which might be confusing for KNN, you can end up with misclassifying plane as ship or vice versa.
  
There are two distance formulas which are called as L1 (Manhattan distance) and L2 (Euclidean distance) formulas (another hyperparameter);
 
L1 Distance;

$$d(I_i, I_j) = \sum_p|I_i^p - I_j^p|$$

and L2 Distance;

$$d(I_i, I_j) = \sqrt{\sum_p(I_i^p - I_j^p)^2}$$

{% highlight ruby %}
while(i < iterate){ //repeats learning for true result 
  while(current room != study room){ //Try different actions and learns untill go to the study room
        action = random_possible_actions
        Q[current room, action] = reward[current room, action] + alpha*max[Q[action, all actions]]
        current room = action
}
i++;
}
{% endhighlight %}

Where alpha is learning rate (0.8). By the way, don't calculate actions rewarded with "-1" since robots can not get through walls :). You should iterate this line of code 
as much as you believe is enough for robot to learn. While iterating you should assign your  actions randomly, so your robot be able to try different roads.

You got your robot learn the road, but how you can test it. Testing code as follows

{% highlight ruby %}
current room = choose some room other than study room
while(current room != study room){
     current room = index(max[Q[current room, all actions]]) // choosing the next room with highest learned reward
     print current room   
 }
{% endhighlight %}

If your room numbers are sequence that creates the shortest way. Then you accomplished to teach your robot the shortest way from kitchen
to your study room. 
Video is also available if you want to check; 

<iframe width="560" height="315" src="//www.youtube.com/embed/uvj-GhsljyA" frameborder="0"> </iframe>
